{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunilrajugaddala96/SUNILRAJU/blob/main/AI_CHATBOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "85d758dc",
      "metadata": {
        "id": "85d758dc"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Optional\n",
        "from pydantic import BaseModel\n",
        "from fastapi import FastAPI, WebSocket, Request, BackgroundTasks\n",
        "import uvicorn\n",
        "import os\n",
        "import logging\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f126d026",
      "metadata": {
        "id": "f126d026"
      },
      "outputs": [],
      "source": [
        "# Optional imports\n",
        "try:\n",
        "    import spacy\n",
        "except Exception:\n",
        "    spacy = None\n",
        "\n",
        "try:\n",
        "    from textblob import TextBlob\n",
        "except Exception:\n",
        "    TextBlob = None\n",
        "\n",
        "# Simple sklearn-based intent classifier (offline demo)\n",
        "try:\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    SKLEARN_AVAILABLE = True\n",
        "except Exception:\n",
        "    SKLEARN_AVAILABLE = False\n",
        "\n",
        "# Redis optional\n",
        "try:\n",
        "    import redis\n",
        "except Exception:\n",
        "    redis = None\n",
        "\n",
        "# OpenAI optional\n",
        "try:\n",
        "    import openai\n",
        "except Exception:\n",
        "    openai = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5aaf81dc",
      "metadata": {
        "id": "5aaf81dc"
      },
      "outputs": [],
      "source": [
        "# Logging / Analytics\n",
        "# --------------------------------------------------\n",
        "logging.basicConfig(level=logging.INFO, filename='chatbot.log', filemode='a',\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger('dynamic_ai_chatbot')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3f672ae3",
      "metadata": {
        "id": "3f672ae3"
      },
      "outputs": [],
      "source": [
        "# Pydantic models for API\n",
        "# --------------------------------------------------\n",
        "class ChatRequest(BaseModel):\n",
        "    user_id: str\n",
        "    text: str\n",
        "    channel: Optional[str] = \"web\"\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "    user_id: str\n",
        "    text: str\n",
        "    intent: Optional[str] = None\n",
        "    entities: Optional[Dict[str, str]] = None\n",
        "    sentiment: Optional[str] = None\n",
        "    source: Optional[str] = \"rule-based\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7523e5ef",
      "metadata": {
        "id": "7523e5ef"
      },
      "outputs": [],
      "source": [
        "# Intent Classifier (simple) - trains on small sample\n",
        "# --------------------------------------------------\n",
        "class IntentClassifier:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.labels = []\n",
        "        if SKLEARN_AVAILABLE:\n",
        "            self.model = Pipeline([\n",
        "                ('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(max_iter=1000))\n",
        "            ])\n",
        "        else:\n",
        "            logger.warning('sklearn not available: using rule-based fallback for intents')\n",
        "\n",
        "    def train(self, texts: List[str], labels: List[str]):\n",
        "        if not SKLEARN_AVAILABLE:\n",
        "            logger.warning('sklearn not available: skipping training')\n",
        "            return\n",
        "        self.labels = sorted(list(set(labels)))\n",
        "        self.model.fit(texts, labels)\n",
        "        logger.info('Intent classifier trained on %d samples' % len(texts))\n",
        "\n",
        "    def predict(self, text: str) -> str:\n",
        "        # If sklearn present, use it; otherwise, fall back\n",
        "        if self.model is not None:\n",
        "            try:\n",
        "                pred = self.model.predict([text])[0]\n",
        "                return pred\n",
        "            except Exception as e:\n",
        "                logger.exception('Intent model prediction failed: %s' % e)\n",
        "        # fallback simple rules\n",
        "        t = text.lower()\n",
        "        if any(w in t for w in ['price', 'cost', 'charge']):\n",
        "            return 'pricing'\n",
        "        if any(w in t for w in ['hello', 'hi', 'hey']):\n",
        "            return 'greeting'\n",
        "        if any(w in t for w in ['bye', 'goodbye', 'see you']):\n",
        "            return 'goodbye'\n",
        "        return 'unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8d68ea70",
      "metadata": {
        "id": "8d68ea70"
      },
      "outputs": [],
      "source": [
        "# NER\n",
        "# --------------------------------------------------\n",
        "class NER:\n",
        "    def __init__(self):\n",
        "        self.nlp = None\n",
        "        if spacy is not None:\n",
        "            try:\n",
        "                # try to load small english model\n",
        "                self.nlp = spacy.load('en_core_web_sm')\n",
        "            except Exception:\n",
        "                # model not installed - user should `python -m spacy download en_core_web_sm`\n",
        "                logger.warning('spaCy model not available. NER will be limited.')\n",
        "                self.nlp = None\n",
        "\n",
        "    def extract(self, text: str) -> Dict[str, str]:\n",
        "        if self.nlp:\n",
        "            doc = self.nlp(text)\n",
        "            return {ent.label_: ent.text for ent in doc.ents}\n",
        "        # fallback regex-based heuristics (very simple)\n",
        "        entities = {}\n",
        "        # dates (very naive)\n",
        "        import re\n",
        "        m = re.search(r'\\b(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\\b', text)\n",
        "        if m:\n",
        "            entities['DATE'] = m.group(1)\n",
        "        # email\n",
        "        m = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
        "        if m:\n",
        "            entities['EMAIL'] = m.group(0)\n",
        "        return entities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1267bb38",
      "metadata": {
        "id": "1267bb38"
      },
      "outputs": [],
      "source": [
        "# Context Manager (conversation memory)\n",
        "# --------------------------------------------------\n",
        "class ContextManager:\n",
        "    def __init__(self, use_redis: bool = False):\n",
        "        self.use_redis = use_redis and (redis is not None)\n",
        "        if self.use_redis:\n",
        "            self.client = redis.Redis()\n",
        "        else:\n",
        "            self.store = {}  # {user_id: [{timestamp, text, response, intent}]}\n",
        "\n",
        "    def append_message(self, user_id: str, message: str, role: str = 'user'):\n",
        "        entry = {'ts': time.time(), 'role': role, 'text': message}\n",
        "        if self.use_redis:\n",
        "            self.client.rpush(f'ctx:{user_id}', json.dumps(entry))\n",
        "        else:\n",
        "            self.store.setdefault(user_id, []).append(entry)\n",
        "\n",
        "    def get_context(self, user_id: str, limit: int = 10) -> List[Dict]:\n",
        "        if self.use_redis:\n",
        "            raw = self.client.lrange(f'ctx:{user_id}', -limit, -1)\n",
        "            return [json.loads(x) for x in raw]\n",
        "        return self.store.get(user_id, [])[-limit:]\n",
        "\n",
        "    def clear_context(self, user_id: str):\n",
        "        if self.use_redis:\n",
        "            self.client.delete(f'ctx:{user_id}')\n",
        "        else:\n",
        "            self.store.pop(user_id, None)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Sentiment analysis\n",
        "# --------------------------------------------------\n",
        "class SentimentAnalyzer:\n",
        "    def analyze(self, text: str) -> str:\n",
        "        try:\n",
        "            if TextBlob is not None:\n",
        "                tb = TextBlob(text)\n",
        "                polarity = tb.sentiment.polarity\n",
        "                if polarity > 0.2:\n",
        "                    return 'positive'\n",
        "                if polarity < -0.2:\n",
        "                    return 'negative'\n",
        "                return 'neutral'\n",
        "        except Exception:\n",
        "            logger.exception('TextBlob sentiment failed')\n",
        "        # naive fallback\n",
        "        low = text.lower()\n",
        "        if any(w in low for w in ['love', 'great', 'thanks']):\n",
        "            return 'positive'\n",
        "        if any(w in low for w in ['hate', 'bad', 'angry']):\n",
        "            return 'negative'\n",
        "        return 'neutral'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fa472d2e",
      "metadata": {
        "id": "fa472d2e"
      },
      "outputs": [],
      "source": [
        "# Response generator (rule-based + GPT fallback)\n",
        "# --------------------------------------------------\n",
        "class ResponseGenerator:\n",
        "    def __init__(self, openai_api_key: Optional[str] = None):\n",
        "        self.openai_api_key = openai_api_key or os.environ.get('OPENAI_API_KEY')\n",
        "        if openai and self.openai_api_key:\n",
        "            openai.api_key = self.openai_api_key\n",
        "\n",
        "    def generate(self, text: str, intent: str, context: List[Dict]) -> Dict:\n",
        "        # First check rule-based responses\n",
        "        r = self.rule_based(text, intent)\n",
        "        if r:\n",
        "            return {'text': r, 'source': 'rule-based'}\n",
        "        # Next, if OpenAI available, call it\n",
        "        if openai and self.openai_api_key:\n",
        "            try:\n",
        "                prompt = self._build_prompt(text, intent, context)\n",
        "                resp = openai.ChatCompletion.create(\n",
        "                    model='gpt-4o-mini' if hasattr(openai, 'ChatCompletion') else 'gpt-3.5-turbo',\n",
        "                    messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "                              {'role': 'user', 'content': prompt}],\n",
        "                    max_tokens=256,\n",
        "                )\n",
        "                # this may vary per OpenAI library version\n",
        "                content = ''\n",
        "                if isinstance(resp, dict) and 'choices' in resp:\n",
        "                    content = resp['choices'][0]['message']['content']\n",
        "                else:\n",
        "                    content = getattr(resp, 'choices')[0].message.content\n",
        "                return {'text': content.strip(), 'source': 'gpt'}\n",
        "            except Exception:\n",
        "                logger.exception('OpenAI call failed - falling back to canned response')\n",
        "        # Default fallback\n",
        "        return {'text': \"Sorry, I didn't understand that. Can you rephrase?\", 'source': 'fallback'}\n",
        "\n",
        "    def rule_based(self, text: str, intent: str) -> Optional[str]:\n",
        "        # Very small set for demo\n",
        "        if intent == 'greeting':\n",
        "            return 'Hello! How can I help you today?'\n",
        "        if intent == 'goodbye':\n",
        "            return 'Goodbye! Have a great day.'\n",
        "        if intent == 'pricing':\n",
        "            return 'Our pricing depends on usage tiers. Would you like to know monthly or annual plans?'\n",
        "        return None\n",
        "\n",
        "    def _build_prompt(self, text: str, intent: str, context: List[Dict]) -> str:\n",
        "        # Build a short context-aware prompt\n",
        "        history = '\\n'.join([f\"{h['role']}: {h['text']}\" for h in context[-6:]])\n",
        "        prompt = f\"Context:\\n{history}\\n\\nUser: {text}\\nIntent: {intent}\\n\\nAssistant:\"\n",
        "        return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "80b61aea",
      "metadata": {
        "id": "80b61aea"
      },
      "outputs": [],
      "source": [
        "# Reinforcement learning stub (records feedback)\n",
        "# --------------------------------------------------\n",
        "class ReinforcementLearner:\n",
        "    def __init__(self):\n",
        "        self.records = []  # In production use persistent DB\n",
        "\n",
        "    def record_feedback(self, user_id: str, query: str, response: str, reward: float):\n",
        "        rec = {'user_id': user_id, 'query': query, 'response': response, 'reward': reward, 'ts': time.time()}\n",
        "        self.records.append(rec)\n",
        "        logger.info('Feedback recorded: %s' % rec)\n",
        "\n",
        "    def summarize(self):\n",
        "        # Example: count positive rewards\n",
        "        return {'total': len(self.records)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "98f6c9ed",
      "metadata": {
        "id": "98f6c9ed"
      },
      "outputs": [],
      "source": [
        "# Putting it together: ChatService\n",
        "# --------------------------------------------------\n",
        "class ChatService:\n",
        "    def __init__(self, use_redis: bool = False):\n",
        "        self.intent = IntentClassifier()\n",
        "        self.ner = NER()\n",
        "        self.ctx = ContextManager(use_redis=use_redis)\n",
        "        self.sent = SentimentAnalyzer()\n",
        "        self.gen = ResponseGenerator()\n",
        "        self.rl = ReinforcementLearner()\n",
        "        # Train a tiny example model if sklearn present\n",
        "        if SKLEARN_AVAILABLE:\n",
        "            sample_texts = ['hello', 'hi there', 'what is the price', 'how much does it cost', 'bye']\n",
        "            sample_labels = ['greeting', 'greeting', 'pricing', 'pricing', 'goodbye']\n",
        "            self.intent.train(sample_texts, sample_labels)\n",
        "\n",
        "    def handle(self, user_id: str, text: str, channel: str = 'web') -> ChatResponse:\n",
        "        # Append user message to context\n",
        "        self.ctx.append_message(user_id, text, role='user')\n",
        "        ctx = self.ctx.get_context(user_id)\n",
        "        # Intent\n",
        "        intent = self.intent.predict(text)\n",
        "        # Entities\n",
        "        entities = self.ner.extract(text)\n",
        "        # Sentiment\n",
        "        sentiment = self.sent.analyze(text)\n",
        "        # Generate response\n",
        "        resp = self.gen.generate(text, intent, ctx)\n",
        "        # Append assistant response to context\n",
        "        self.ctx.append_message(user_id, resp['text'], role='assistant')\n",
        "        # Log analytics\n",
        "        logger.info(json.dumps({\n",
        "            'user_id': user_id, 'text': text, 'intent': intent, 'entities': entities,\n",
        "            'sentiment': sentiment, 'response_source': resp.get('source')\n",
        "        }))\n",
        "        return ChatResponse(user_id=user_id, text=resp['text'], intent=intent, entities=entities,\n",
        "                            sentiment=sentiment, source=resp.get('source'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "17eeddc6",
      "metadata": {
        "id": "17eeddc6"
      },
      "outputs": [],
      "source": [
        "# FastAPI app: endpoints for REST + WebSocket\n",
        "# --------------------------------------------------\n",
        "app = FastAPI(title='Dynamic AI Chatbot - Demo')\n",
        "service = ChatService(use_redis=False)\n",
        "\n",
        "@app.post('/chat', response_model=ChatResponse)\n",
        "async def chat_endpoint(req: ChatRequest):\n",
        "    res = service.handle(req.user_id, req.text, req.channel)\n",
        "    return res\n",
        "\n",
        "# Simple webhook-style endpoints for Slack / WhatsApp (demo placeholders)\n",
        "@app.post('/webhook/slack')\n",
        "async def slack_webhook(request: Request):\n",
        "    payload = await request.json()\n",
        "    # Slack event parsing logic goes here (verification, event type)\n",
        "    user_id = payload.get('user', 'slack_user')\n",
        "    text = payload.get('text', '')\n",
        "    resp = service.handle(user_id, text, channel='slack')\n",
        "    # You'd respond with a JSON response according to Slack API or call chat.postMessage\n",
        "    return {'ok': True, 'reply': resp.text}\n",
        "\n",
        "@app.post('/webhook/whatsapp')\n",
        "async def whatsapp_webhook(request: Request):\n",
        "    payload = await request.json()\n",
        "    user_id = payload.get('from', 'wa_user')\n",
        "    text = payload.get('message', '')\n",
        "    resp = service.handle(user_id, text, channel='whatsapp')\n",
        "    return {'status': 'ok', 'reply': resp.text}\n",
        "\n",
        "# WebSocket echo-style chat (for real-time UI)\n",
        "@app.websocket('/ws/{user_id}')\n",
        "async def websocket_endpoint(websocket: WebSocket, user_id: str):\n",
        "    await websocket.accept()\n",
        "    try:\n",
        "        while True:\n",
        "            data = await websocket.receive_text()\n",
        "            res = service.handle(user_id, data, channel='websocket')\n",
        "            await websocket.send_text(json.dumps(res.dict()))\n",
        "    except Exception:\n",
        "        await websocket.close()\n",
        "\n",
        "# Feedback endpoint for RL\n",
        "class FeedbackRequest(BaseModel):\n",
        "    user_id: str\n",
        "    query: str\n",
        "    response: str\n",
        "    reward: float\n",
        "\n",
        "@app.post('/feedback')\n",
        "async def feedback(req: FeedbackRequest):\n",
        "    service.rl.record_feedback(req.user_id, req.query, req.response, req.reward)\n",
        "    return {'ok': True}\n",
        "\n",
        "# Simple analytics endpoint summarizing logs (demo)\n",
        "@app.get('/analytics/summary')\n",
        "async def analytics_summary():\n",
        "    # In production parse a DB or analytics store\n",
        "    total_msgs = 0\n",
        "    intents = {}\n",
        "    try:\n",
        "        with open('chatbot.log', 'r') as f:\n",
        "            for line in f:\n",
        "                total_msgs += 1\n",
        "                try:\n",
        "                    # attempt to parse JSON payload inside the log line\n",
        "                    if '{' in line:\n",
        "                        j = json.loads(line.split(' - ', 2)[-1])\n",
        "                        intents[j.get('intent', 'unknown')] = intents.get(j.get('intent', 'unknown'), 0) + 1\n",
        "                except Exception:\n",
        "                    pass\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "    return {'total_log_lines': total_msgs, 'intent_counts': intents, 'rl_records': service.rl.summarize()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ecab77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ecab77",
        "outputId": "d2b8de6d-2b66-46e1-c62f-8e57bf0bf9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Will watch for changes in these directories: ['/content']\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "INFO:     Started reloader process [5147] using StatReload\n"
          ]
        }
      ],
      "source": [
        "# Main (for local testing)\n",
        "# --------------------------------------------------\n",
        "import uvicorn\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(\"dynamic_ai_chatbot:app\", host=\"0.0.0.0\", port=8000, reload=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2100a467",
      "metadata": {
        "id": "2100a467"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}